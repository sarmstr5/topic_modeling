{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "from scipy.sparse import coo_matrix, csc_matrix, csr_matrix\n",
    "import sklearn as sk\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_type, fn):\n",
    "    npy_file = np.load(fn)\n",
    "    if dataset_type == 'csc':\n",
    "        return csc_matrix((npy_file['data'], npy_file['indices'], npy_file['indptr']), shape=npy_file['shape'])\n",
    "    else:\n",
    "        return csr_matrix((npy_file['data'], npy_file['indices'], npy_file['indptr']), shape=npy_file['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(dataset_type, fn):\n",
    "    files = glob.glob('*'+dataset_type+'.npz')\n",
    "    for fn in files:\n",
    "        npy_file = np.load(fn)\n",
    "        if dataset_type == 'csc':\n",
    "            yield csc_matrix((npy_file['data'], npy_file['indices'], npy_file['indptr']), shape=npy_file['shape'])\n",
    "        else:\n",
    "            yield csr_matrix((npy_file['data'], npy_file['indices'], npy_file['indptr']), shape=npy_file['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' pubmed_rows', 'docword.enron.txt', 'docword.enron.txt_csc.npz', 'docword.enron.txt_csr.npz', 'docword.kos.txt', 'docword.kos.txt_csc.npz', 'docword.kos.txt_csr.npz', 'docword.nips.txt', 'docword.nips.txt_csc.npz', 'docword.nips.txt_csr.npz', 'docword.pubmed.txt', 'docword.pubmed.txt_csc.npz', 'docword.pubmed.txt_csr.npz', 'docword.pubmed.zip', 'processed', 'raw', 'readme.txt', 'trunc_pubmed.txt', 'vocab.enron.txt', 'vocab.kos.txt', 'vocab.nips.txt', 'vocab.nytimes.txt', 'vocab.pubmed.txt']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'CS674/HW4_topic_modeling/data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-490e503fbf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CS674/HW4_topic_modeling/data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'CS674/HW4_topic_modeling/data'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(glob.glob(\"*\"))\n",
    "os.chdir(\"CS674/HW4_topic_modeling/data\")\n",
    "glob.glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time complexity is proportional to (n_samples * iterations)\n",
    "n_topics = 5\n",
    "learning_method = 'online' # due to size of matrix\n",
    "n_jobs = -2 # parallel run\n",
    "max_iter = 5 # default is 10\n",
    "lda_model = sk.decomposition.LatentDirichletAllocation(n_topics=n_topics, doc_topic_prior=None, topic_word_prior=None, learning_method=learning_method, \n",
    "                          learning_decay=0.7, learning_offset=10.0, max_iter=max_iter, batch_size=128, evaluate_every=-1, \n",
    "                          total_samples=1000000.0, perp_tol=0.1, mean_change_tol=0.001, max_doc_update_iter=100, n_jobs=n_jobs, \n",
    "                          verbose=0, random_state=None)\n",
    "# lda = decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy run\n",
    "fn = 'docword.nips.txt_csc.npz'\n",
    "fn_vocab = 'vocab.nips.txt'\n",
    "dataset_type = 'csc'\n",
    "nips_csc = load_dataset(dataset_type, fn)\n",
    "nips_vocab = load_vocab(fn_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(fn):\n",
    "    nips_voc = []\n",
    "    with open(fn) as file:\n",
    "        for row in file:\n",
    "            nips_voc.append(row.strip())\n",
    "    return np.array(nips_voc)\n",
    "    # nips_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1501x12420 sparse matrix of type '<class 'numpy.int32'>'\n\twith 746316 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips_csc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_x = lda_model.fit_transform(nips_csc)\n",
    "lda_model.fit(nips_csc)\n",
    "document_topics = lda_model.transform(nips_csc)\n",
    "topic_terms = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15010\n(1501, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lda_x.size)\n",
    "print(lda_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.02309501e-01,   2.66373557e-02,   4.18623015e-01,\n         6.54297978e-02,   1.80284978e-01,   2.34274188e-04,\n         5.45115749e-02,   1.70550187e-02,   4.49533955e-02,\n         8.99610890e-02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_x[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n 'doc_topic_prior': None,\n 'evaluate_every': -1,\n 'learning_decay': 0.7,\n 'learning_method': 'online',\n 'learning_offset': 10.0,\n 'max_doc_update_iter': 100,\n 'max_iter': 5,\n 'mean_change_tol': 0.001,\n 'n_jobs': -2,\n 'n_topics': 10,\n 'perp_tol': 0.1,\n 'random_state': None,\n 'topic_word_prior': None,\n 'total_samples': 1000000.0,\n 'verbose': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 12420)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_terms = lda_model.components_\n",
    "topic_terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.10391615,   0.1040452 ,   0.89426193, ...,   0.10474264,\n          0.10326578,   0.10841106],\n       [  0.1036645 ,   0.11036951,   0.10483775, ...,   0.10702023,\n          1.9999361 ,   5.2537496 ],\n       [  0.10423169,   9.93861039,  17.03310735, ...,   3.31347389,\n          0.73386314,   0.10963228],\n       ..., \n       [  0.10343269,   0.10383289,   0.40434516, ...,   0.11256667,\n          6.98703235,   0.19761039],\n       [  0.10355895,   0.10431877,   0.10502626, ...,   0.10399279,\n          0.10527757,   2.09395661],\n       [  0.10341513,   0.10349258,   0.10346987, ...,   0.10466567,\n          0.10846652,   0.66358857]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-bb7c035a77e8>, line 2)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-bb7c035a77e8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def get_top_topic_words(k, topic_terms):\n",
    "    for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topic_terms = []\n",
    "k = 20\n",
    "for top_num, topic in enumerate(topic_terms):\n",
    "    print(type(topic))\n",
    "    topic_list = topic.tolist()\n",
    "    print(topic_list)\n",
    "    # topic_heap = heapq._heapify_max(topic.tolist())\n",
    "    # print(topic_heap)\n",
    "    # top_terms = nlargest(k, topic)\n",
    "    # print(topic_heap.pop)\n",
    "    # top_topic_terms.append(top_terms)\n",
    "# top_topic_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1103  3826  1537  7391  6787 11719  7874  7011  7358  2503  2961  4736\n 11020  7365  8461 10993  7118  4034 11907  5399]\n[ 2804  1128  4330  4270 12018 10145 12153 12042  5164 11244 11020   415\n  2503  7874  7358  1729  7365  5399  1665  7391]\n[ 8370 12153  9402  8628  3603  7969  4270  3080 10003  7365  6120 11418\n 11901  5399   316  7358  7579  2574  6836  7011]\n[ 7811  4270  7358  5344 10993 11020 10145  2368  4232  3979  8051  5399\n  9382   137 10498  1537 10644 12001  7011  7391]\n[ 8640  5263  9967  6980  7787  6676  1864   428   316 12125 10145  5344\n  1150 10408 10409  2023  7279  5002  4001  4270]\n[10368  7963  7579  1128  9402  7365 11901  2574   316 11814 10003  7011\n  6120  8051  8628  6796  7358 11020  8140 11719]\n[ 2626  9480 10215  7459 11444  8417   672  1855  5265  5763  1158 10376\n  4853  2586  2886  4611  8395  2107  6736  6862]\n[ 8304  7874  7365  6093  5344  8370 11020  9306  7358  7600  5118 11719\n  5399  2574  3915  3916  9059  5120  7011 10003]\n[10620  3534  4270  7124  9456  8628  8427  2263 11078  9556  7136  7358\n  3240 11020  6120  9206  7011  2260   126  8385]\n[11078 11417  8051  6093 11418 10472  4803 11719  9059  7874 12263  7011\n  5399  7358  4854 11020 10003  2221  7365  7349]\n"
     ]
    }
   ],
   "source": [
    "top_topic_inds = []\n",
    "top_topic_terms = []\n",
    "k = 20\n",
    "for top_num, topic in enumerate(topic_terms):\n",
    "    topic_sorted = np.argpartition(topic, -k)[-k:]\n",
    "    \n",
    "    top_topic_inds.append(topic_sorted)\n",
    "# top_topic_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['stephen', 'environmental', 'functional', 'motorola', 'rewarded',\n       'problematic', 'positional', 'controlling', 'tat', 'robotic',\n       'moves', 'netxvork', 'dynamical', 'systematic', 'learnt',\n       'reiterant', 'modeled', 'controllable', 'activ', 'pollack'], \n      dtype='<U23')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips_vocab[top_topic_inds[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}